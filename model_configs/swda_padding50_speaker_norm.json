{
  "name": "swda_padding25_speaker_norm",
  "model": "attention",
  "dataset": "swbd",
  "input_unit": "word",
  "vocab_file": "data/swbd/vocab/words_swda.txt",
  "train_data": "data/swbd/inputs_swda_padding25_speaker_norm_train.txt",
  "eval_data": "data/swbd/inputs_swda_padding25_speaker_norm_test.txt",

  "learning_rate": 1e-3,
  "batch_size": 32,
  "eval_batch_size": 50,

  "learning_rate_start_decay_epoch": 15,
  "learning_rate_decay_steps": 2,
  "learning_rate_decay_rate": 0.5,

  "encoder_type": "pbilstm",
  "encoder_num_units": 640,
  "decoder_num_units": 640,
  "attention_num_units": 640,
  "attention_layer_size": 640,
  "output_attention": true,

  "beam_width": 16,
  "length_penalty_weight": 0.5,
  "max_gradient_norm": 5.0
}
