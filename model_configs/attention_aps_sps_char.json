{
  "model": "attention",
  "dataset": "default",
  "vocab_file": "data/aps-sps/char.id",
  "train_data": "data/aps-sps/train/char_sort_xlen.txt",
  "test_data": "data/aps-sps/test/char_targets.txt",
  "encoding": "euc-jp",
  "metrics": "wer",

  "batch_size": 30,
  "eval_batch_size": 30,

  "use_sos_eos": false,
  "learning_rate": 1e-4,
  "learning_rate_start_decay_epoch": 7,
  "learning_rate_decay_steps": 1,
  "learning_rate_decay_rate": 0.5,

  "eos_index": 0,
  "sos_index": 1,
  "use_encoder_final_state": false,
  "encoder_type": "bilstm",
  "encoder_num_units": 640,
  "num_encoder_layers": 3,
  "decoder_num_units": 640,
  "num_decoder_layers": 1,
  "attention_num_units": 640,
  "attention_layer_size": 640,
  "location_attention_width": 201,
  "output_attention": true,

  "beam_width": 16,
  "length_penalty_weight": 0.5,
  "max_gradient_norm": 5.0,
  "max_epoch_num": 40
}
