{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob, os\n",
    "TEST_DATA_FOLDERS = [\n",
    "    \"/n/sd7/trung/csp/data/erica/annotation/test/interview\",\n",
    "    \"/n/sd7/trung/csp/data/erica/annotation/test/dating\",\n",
    "    \"/n/sd7/trung/csp/data/erica/annotation/test/attentive\"\n",
    "]\n",
    "TRAIN_DATA_FOLDERS = [\n",
    "    \"/n/sd7/trung/csp/data/erica/annotation/kyoto17/spring/interview\",\n",
    "    \"/n/sd7/trung/csp/data/erica/annotation/kyoto17/spring/dating\",\n",
    "    \"/n/sd7/trung/csp/data/erica/annotation/kyoto17/spring/attentive\",\n",
    "    \"/n/sd7/trung/csp/data/erica/annotation/kyoto16/interview\",\n",
    "    \"/n/sd7/trung/csp/data/erica/annotation/kyoto16/dating\",\n",
    "    \"/n/sd7/trung/csp/data/erica/annotation/kyoto16/attentive\",\n",
    "    \"/n/sd7/trung/csp/data/erica/annotation/kyoto16/labintro\",\n",
    "]\n",
    "\n",
    "mode = \"train\"\n",
    "\n",
    "from subprocess import call\n",
    "from struct import unpack, pack\n",
    "import numpy as np\n",
    "\n",
    "import IPython\n",
    "import wave\n",
    "from pydub import AudioSegment\n",
    "import re\n",
    "\n",
    "import MeCab\n",
    "mt = MeCab.Tagger(\"-Owakati\")\n",
    "mt.parse('')\n",
    "\n",
    "OUTPUT_FOLDER = \"/n/sd7/trung/csp/data/erica\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab Size: 30638\n"
     ]
    }
   ],
   "source": [
    "words = [s.strip().split(' ', 1) for s in open('/n/rd32/mimura/e2e/data/script/aps_sps/word.id', encoding='eucjp')]\n",
    "decoder_map_word = {word[0].split('+')[0]: int(word[1]) for word in words}\n",
    "\n",
    "# words = [s.strip().split(' ', 1) for s in open('/n/sd7/trung/csp/data/erica/word_ids.txt') if s != \"\"]\n",
    "# decoder_map_word = {word[0]: int(word[1]) for word in words}\n",
    "# decoder_map_word = {'<unk>': 0, '<sos>': 1, '<eos>': 2, '<sp>': 3}\n",
    "print(\"Vocab Size:\", len(decoder_map_word))\n",
    "\n",
    "TAG_COUNT = 17\n",
    "def get_tag_id(tag):\n",
    "    for i, t in enumerate(['pQ', 'cQ', 'sQ', 'checkQ', 'inf', 'off', 'pro', 'sug', 'req', 'ans', 'arg', 'disarg', 'cor', 'acc', 'dec', 'bc', 'oth']):\n",
    "        if tag.startswith(t): return i\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = {}\n",
    "def get_word_id(word, oov, line, return_word=False):\n",
    "    '''\n",
    "    if word == '　': return ['<sp>']\n",
    "    if mode == \"train\" or word in decoder_map_word: \n",
    "        if word in vocab: vocab[word] += 1\n",
    "        else: \n",
    "            vocab[word] = 1\n",
    "            return [word]\n",
    "    else:\n",
    "        if word in oov: oov[word] += 1\n",
    "        else: oov[word] = 1\n",
    "        return [word]\n",
    "    '''\n",
    "    \n",
    "    ret = []\n",
    "    start = 0\n",
    "    end = len(word)\n",
    "    while start < len(word):\n",
    "        if start >= end: \n",
    "            if word in oov: oov[word] += 1\n",
    "            else: \n",
    "                oov[word] = 1\n",
    "                # print(line, word)\n",
    "            # return ret + [-1]\n",
    "            return ['<UNK>'] if return_word else [decoder_map_word['<UNK>']]\n",
    "        if word[start:end] in decoder_map_word:\n",
    "            if not return_word: ret.append(decoder_map_word[word[start:end]])\n",
    "            else: ret.append(word[start:end])\n",
    "            start = end\n",
    "            end = len(word)\n",
    "        else:\n",
    "            end -= 1\n",
    "    return ret\n",
    "\n",
    "def split_words(s, oov, return_word=False):\n",
    "    s = \" \".join(s)\n",
    "    s.replace(\"　\", \" \")\n",
    "    #s = s.replace(' <', '<')\n",
    "    #s = s.replace(' ', ' <sp> ')\n",
    "    #s = s.replace('<', ' <')\n",
    "    s = s.split(' ')\n",
    "    ret = []\n",
    "    for ss in s:\n",
    "        ss = ss.replace(' ', '')\n",
    "        if ss and ss[0] =='<':\n",
    "            ret.append(ss if return_word else decoder_map_word['<sp>'])\n",
    "            continue\n",
    "        if ss == '': continue\n",
    "        tokens = mt.parse(ss).strip()\n",
    "        tokens = tokens.split(' ')\n",
    "        for t in tokens:\n",
    "            ret += get_word_id(t, oov, s, return_word)\n",
    "    return ret\n",
    "    \n",
    "def preproc(line):\n",
    "    for c in ['I', 'L', 'F', 'D', 'N']:\n",
    "        line = re.sub(r'\\(' + c + '([^\\)]*)\\)', r'\\1', line)\n",
    "    line = re.sub(r'\\(\\?([^\\)]*)\\)', r'\\1', line)\n",
    "    for c in list('`\"「」') + ['(L', 'L)', '(F', ' L']:\n",
    "        line = line.replace(c, '')\n",
    "    line = re.sub(r'%.*', r'', line)\n",
    "        \n",
    "    line = line.replace('{LAUGH}', '')\n",
    "    line = line.replace('{LAuGH}', '')\n",
    "    line = line.replace('{COUGH}', '')\n",
    "    line = re.sub(r'\\(P [0-9]*\\)', r'', line)\n",
    "    \n",
    "    k = line.find('/')\n",
    "    if k != -1:\n",
    "        tags = [line[k + 1:].split(';')[0]]\n",
    "        line = line[:k]\n",
    "    else: tags = []\n",
    "        \n",
    "    env = None\n",
    "    for i in range(len(tags)):\n",
    "        if tags[i].find('/') >= 0:\n",
    "            env, tags[i] = tags[i].split('/', maxsplit=1)\n",
    "    # tags = re.findall(r'\\/(\\w*)', line)\n",
    "    line = re.sub(r'\\/\\w*', '', line)\n",
    "    # if len(tags) > 0: line += \"<\" + tags[0] + \">\"\n",
    "    # if len(tags) > 1: print(tags)\n",
    "    # print(line)\n",
    "    return line.strip(), tags, env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepaths = []\n",
    "targets = []\n",
    "\n",
    "targets = []\n",
    "oov = {}\n",
    "for DATA_FOLDER in TEST_DATA_FOLDERS if mode == \"test\" else TRAIN_DATA_FOLDERS:\n",
    "    for file in glob.glob(os.path.join(DATA_FOLDER, \"*.txt\")):\n",
    "        is_start = True\n",
    "        date, id, obj = os.path.basename(file)[:-4].split('_')[:3]\n",
    "        longid = date + \"_\" + id\n",
    "        year = date[:4]\n",
    "        \n",
    "        # if longid != \"20171128_03\": continue\n",
    "        \n",
    "        encoding = 'shift-jis'\n",
    "        if longid in ['20161205_03', '20161209_05', '20161215_04', '20161208_03', '20161205_07', '20161212_01', '20161209_04', \n",
    "                      '20161209_03', '20161208_01', '20161212_03', '20161208_02', '20161207_05', '20161215_03', '20161207_04',\n",
    "                     '20161205_04']: encoding = 'utf-8'\n",
    "        \n",
    "        lines = open(file, encoding=encoding).read().split('\\n')\n",
    "        # print(lines)\n",
    "\n",
    "        k = 0\n",
    "        while k < len(lines):\n",
    "            line = lines[k].strip()\n",
    "            if longid == '20161209_05':\n",
    "                start, end = line.split(' ')[1:3]\n",
    "            else:\n",
    "                start, end = line.split(' ')[1].split('-')\n",
    "            start, end = float(start) * 1000, float(end) * 1000\n",
    "            utt_id = line.split(' ')[0]\n",
    "\n",
    "            output_wav = os.path.join(OUTPUT_FOLDER, \"wav\", longid, \"%s_%s.wav\" % (utt_id, obj))\n",
    "            output_htk = os.path.join(OUTPUT_FOLDER, \"htk\", longid, \"%s_%s.htk\" % (utt_id, obj))\n",
    "            output_npy = os.path.join(OUTPUT_FOLDER, \"npy\", longid, \"%s_%s.npy\" % (utt_id, obj))\n",
    "            \n",
    "            if line[-2:] == obj + ':':\n",
    "                k += 1\n",
    "                s = []\n",
    "                tags = []\n",
    "                envs = set()\n",
    "                while k < len(lines):\n",
    "                    line = lines[k].strip()\n",
    "                    if line[-2:] == obj + ':': break\n",
    "\n",
    "                    line, tag, env = preproc(line)\n",
    "                    if env: envs.add(env)\n",
    "                    if tag: tags += tag\n",
    "                    if line != '': s.append(line)\n",
    "                    # if len(tag) > 0: s.append(\"<\" + tag[0] + \">\")\n",
    "                    k += 1\n",
    "                    \n",
    "                dtag = ['0'] * TAG_COUNT\n",
    "                for tag in tags:\n",
    "                    id = get_tag_id(tag)\n",
    "                    if id is not None: dtag[id] = '1'\n",
    "                \n",
    "                s = split_words(s, oov, False)\n",
    "                tags = '_'.join([';'.join(tag) for tag in tags])\n",
    "                \n",
    "                if len(s) >= 2 and float(end) - float(start) < 10000:\n",
    "                    #targets.append(' '.join([str(k) for k in s]))\n",
    "                    targets.append((longid, start, end, obj, ' '.join(dtag), ' '.join([str(k) for k in s]), is_start))\n",
    "                    is_start = False\n",
    "                    #targets.append(\"%s %07d %07d %s %s %s %s\" % (longid, start, end, utt_id, obj, ''.join(list(envs)) or '_', s))\n",
    "                    filepaths.append(output_npy)\n",
    "            else: k += 1\n",
    "\n",
    "ls = list(zip(targets, filepaths))\n",
    "ls.sort()\n",
    "targets, filepaths = zip(*ls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Utterences: 23491\n"
     ]
    }
   ],
   "source": [
    "print(\"Utterences:\", len(filepaths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab Size: 0\n",
      "[]\n",
      "OOV: 448\n",
      "[('ー', 1874), ('ご存知', 34), ('致し', 29), ('らっしゃる', 28), ('っ', 26), ('ヤ', 20), ('なくっ', 18), ('かなっ', 18), ('ガ', 13), ('綺麗', 13), ('らっしゃい', 12), ('ヨ', 12), ('ご覧', 11), ('ネ', 11), ('ゾンビ', 11), ('・', 10), ('かかっ', 9), ('といった', 9), ('(', 9), ('高槻', 9), ('。', 8), ('らっしゃっ', 8), ('友禅', 8), ('等持院', 8), ('インタラクション', 8), ('ズ', 7), ('おしゃれ', 7), ('沢山', 7), ('祐介', 7), ('ヤドカリ', 7), (')', 6), ('烏丸', 6), ('下賀茂', 6), ('００７', 6), ('ゅう', 6), ('伺える', 6), ('上賀茂', 5), ('餃子', 5), ('P', 5), ('止', 5), ('就活', 4), ('＋', 4), ('奴', 4), ('ダイガ', 4), ('ジャガイモ', 4), ('橿原', 4), ('メットガラ', 4), ('匂い', 4), ('サムギョプサル', 4), ('ウィンドウズ', 4), ('フレンズ', 4), ('ヨシ', 3), ('リョ', 3), ('キョ', 3), ('糺', 3), ('断', 3), ('ボーカロイド', 3), ('混ん', 3), ('ミッションインポッシブル', 3), ('持', 3), ('オッケー', 3), ('キョウ', 3), ('経っ', 3), ('ヒマラヤスギ', 3), ('退室', 3), ('申', 3), ('流行っ', 3), ('いいっ', 3), ('晴子', 3), ('ヶ月', 3), ('莉子', 3), ('シンセサイザー', 3), ('雀', 3), ('昌弘', 3), ('パフェ', 3), ('マニャガハ', 3), ('ピギー', 3), ('釣ろ', 3), ('梨々子', 3), ('採譜', 3), ('カンパニー', 2), ('試薬', 2), ('斎藤', 2), ('萌', 2), ('チョット', 2), ('露木', 2), ('ソウデスネ', 2), ('惹か', 2), ('ガン', 2), ('採れ', 2), ('ジャ', 2), ('きたっ', 2), ('鋼', 2), ('錬金術', 2), ('紋', 2), ('ガー', 2), ('\\u3000', 2), ('っきり', 2), ('ハッ', 2), ('橿原神宮', 2), ('ソウネ', 2), ('ショーン・オブ・ザ・デッド', 2), ('オヤ', 2), ('信也', 2), ('チュ', 2), ('智也', 2), ('コンピュータ', 2), ('１', 2), ('ガチ', 2), ('然', 2), ('シネマ', 2), ('ラ・ラ・ランド', 2), ('ビッ', 2), ('ホッ', 2), ('祭典', 2), ('漬物', 2), ('之', 2), ('介', 2), ('チュパー', 2), ('L', 2), ('タブレット', 2), ('濱田', 2), ('庄司', 2), ('才', 2), ('ゾ', 2), ('スギ', 2), ('掃か', 2), ('ズク', 2), ('厨子', 2), ('沁み', 2), ('ンー', 2), ('えーっ', 2), ('暗算', 2), ('悠', 2), ('読', 2), ('ヲ', 2), ('泡盛', 2), ('ウィンドー', 2), ('ゅっていう', 2), ('スネ', 2), ('治験', 2), ('00918', 2), ('.', 2), ('トヨ', 2), ('うつっ', 2), ('シズ', 2), ('おじいちゃん', 2), ('ウミガメ', 2), ('ピギイ', 2), ('廃墟', 2), ('浅', 2), ('浅海', 2), ('ゅうのは', 2), ('重奏', 2), ('王将', 2), ('大慶', 1), ('哲也', 1), ('懸け橋', 1), ('トートロジー', 1), ('ジュー', 1), ('セー', 1), ('断れ', 1), ('磨か', 1), ('断る', 1), ('仰せつかり', 1), ('充てる', 1), ('チヤ', 1), ('周遊', 1), ('願え', 1), ('購読', 1), ('ハヤ', 1), ('挿絵', 1), ('ダブルダッチ', 1), ('縮こまっ', 1), ('充分', 1), ('ありがたくっ', 1), ('ガードガ', 1), ('ヤッパ', 1), ('臨める', 1), ('腫瘍', 1), ('ヨユ', 1), ('トリュ', 1), ('シュー', 1), ('担える', 1), ('シュミレーションモデル', 1), ('シュミレーション', 1), ('挫け', 1), ('シンギュラリティ', 1), ('D', 1), ('）', 1), ('オッシァエ', 1), ('理沙', 1), ('ナガ', 1), ('ナガラ', 1), ('滋養', 1), ('恵', 1), ('ヨウ', 1), ('ょお', 1), ('浅くっ', 1), ('聡', 1), ('定休', 1), ('捨離', 1), ('デシタッケ', 1), ('フネ', 1), ('ヤッテマシ', 1), ('チェ', 1), ('寝っ転がり', 1), ('デスカネ', 1), ('ドヴォルザーク', 1), ('ソット', 1), ('ケッコ', 1), ('アジャ', 1), ('ヒョ', 1), ('ナー', 1), ('タッ', 1), ('非常勤', 1), ('ツァ', 1), ('パッ', 1), ('映さ', 1), ('ウズ', 1), ('コウヨウ', 1), ('ナルホドネ', 1), ('ツヨ', 1), ('ファッジ', 1), ('ケッコウ', 1), ('オンガクトカ', 1), ('多くっ', 1), ('ヒューマンズ', 1), ('スポーティ', 1), ('さしかかっ', 1), ('詳し', 1), ('ヤム', 1), ('ッテ', 1), ('ガッ', 1), ('混む', 1), ('停', 1), ('延', 1), ('ドキュン', 1), ('チョッ', 1), ('チガ', 1), ('メット', 1), ('こもっ', 1), ('ヨイ', 1), ('アキ・カウリスマキ', 1), ('ドー', 1), ('トー', 1), ('秘話', 1), ('聡子', 1), ('鎮座', 1), ('ガチャガチャ', 1), ('イヤ', 1), ('チュウガッ', 1), ('しんどくっ', 1), ('葵', 1), ('カヨ', 1), ('止ん', 1), ('眠たい', 1), ('ニー', 1), ('診', 1), ('水越', 1), ('ワヤ', 1), ('釉薬', 1), ('オッシャ', 1), ('断ら', 1), ('テンジョ', 1), ('パネ', 1), ('分っ', 1), ('置物', 1), ('ヒヤ', 1), ('コンズ', 1), ('キンジョニ', 1), ('ゅうのが', 1), ('ゅうような', 1), ('掃こ', 1), ('ゅうたら', 1), ('ゅうてね', 1), ('リッタ', 1), ('ギュー', 1), ('籠っ', 1), ('集っ', 1), ('ギリギリ', 1), ('如く', 1), ('空也', 1), ('弔う', 1), ('お断り', 1), ('クリップ', 1), ('ダンヨウ', 1), ('ヤマ', 1), ('急遽', 1), ('566', 1), ('烏丸線', 1), ('フェスネ', 1), ('フスネ', 1), ('ワーッ', 1), ('引っかかる', 1), ('只今', 1), ('採否', 1), ('接', 1), ('々', 1), ('トッ', 1), ('202', 1), ('リョウ', 1), ('ミョウ', 1), ('勉', 1), ('コミニュケーション', 1), ('コヌ', 1), ('這いつくばっ', 1), ('アリガトウゴザイマス', 1), ('ヒガ', 1), ('リュ', 1), ('オカガトヒ', 1), ('ツッ', 1), ('410', 1), ('セッキョコクス', 1), ('そろっ', 1), ('貯めよ', 1), ('生っ', 1), ('曲っ', 1), ('インストゥルメンタル', 1), ('控室', 1), ('法曹', 1), ('退い', 1), ('シマズッテ', 1), ('突っぱっ', 1), ('突っ走り', 1), ('範ちゅう', 1), ('ビックバンド', 1), ('キュレーション', 1), ('忙', 1), ('浅かっ', 1), ('ジョウ', 1), ('モギ', 1), ('ボウズ', 1), ('晴', 1), ('永観堂', 1), ('オッカ', 1), ('塗布', 1), ('消', 1), ('賄わ', 1), ('≈', 1), ('クギ', 1), ('海鮮', 1), ('ょっか', 1), ('不詳', 1), ('早くっ', 1), ('208', 1), ('ポリマー', 1), ('ヌ', 1), ('0331', 1), ('049', 1), ('-', 1), ('898', 1), ('S', 1), (':', 1), ('キョイ', 1), ('ガシ', 1), ('ガシュソガ', 1), ('歓', 1), ('サッサ', 1), ('ノッツ', 1), ('ダーク', 1), ('スネー', 1), ('キョウズ', 1), ('叡山', 1), ('ヤフ', 1), ('キャーンペ', 1), ('多才', 1), ('ポロッ', 1), ('シャガール', 1), ('ゾクッ', 1), ('引越し', 1), ('康弘', 1), ('ヤス', 1), ('ヌノダ', 1), ('栄', 1), ('清楚', 1), ('f', 1), ('リョコ', 1), ('ダイネ', 1), ('いやー', 1), ('かわっ', 1), ('翔', 1), ('シュッチン', 1), ('ズン', 1), ('童顔', 1), ('ひしゃ', 1), ('ヤヤ', 1), ('アグリー・ベティ', 1), ('カヤ', 1), ('専', 1), ('スズ', 1), ('392', 1), ('i', 1), ('緩かっ', 1), ('狭くっ', 1), ('セーフ', 1), ('ガンバ', 1), ('ヤリン', 1), ('ドーレー', 1), ('ドーロー', 1), ('カギカ', 1), ('可哀想', 1), ('落し物', 1), ('詩仙堂', 1), ('ストロベリーフィールズ', 1), ('ターミネーター', 1), ('ヤダ', 1), ('バッ', 1), ('憶え', 1), ('ヨーロ', 1), ('ジッ', 1), ('実演', 1), ('遅くっ', 1), ('スーッ', 1), ('要塞', 1), ('おじゃん', 1), ('錘', 1), ('ボー', 1), ('ウット', 1), ('仕掛', 1), ('察', 1), ('マナガハ', 1), ('ヤサ', 1), ('チューバ', 1), ('テムズ', 1), ('佳', 1), ('梨', 1), ('チョッキ', 1), ('見付かっ', 1), ('受付', 1), ('失', 1), ('おっきくっ', 1), ('シガ', 1), ('おっちょこちょい', 1), ('フィギ', 1), ('ンヌ', 1), ('引っかかっ', 1), ('ソックス', 1), ('ニヤヤ', 1), ('引っ', 1), ('登頂', 1), ('尚', 1), ('且つ', 1), ('違', 1), ('仰っ', 1), ('５', 1), ('ラッシャン', 1), ('テー', 1)]\n"
     ]
    }
   ],
   "source": [
    "_vocab = { word: vocab[word] for word in vocab if vocab[word] >2 } if mode == \"train\" else vocab\n",
    "import operator\n",
    "sorted_words = sorted(_vocab.items(), key=operator.itemgetter(1), reverse=True)\n",
    "print(\"Vocab Size:\", len(sorted_words))\n",
    "print(sorted_words)\n",
    "\n",
    "print(\"OOV:\", len(oov))\n",
    "sorted_oov = sorted(oov.items(), key=operator.itemgetter(1), reverse=True)\n",
    "print(sorted_oov)\n",
    "\n",
    "if mode == \"train\":\n",
    "    with open(os.path.join(OUTPUT_FOLDER, 'word_ids.txt'), 'w') as f:\n",
    "        f.write('\\n'.join(['<unk> 0', '<sos> 1', '<eos> 2', '<sp> 4\\n']))\n",
    "        for i, word in enumerate(sorted_words): f.write('%s %d\\n' % (word[0], i + 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(filepaths)\n",
    "#print('\\n'.join([t for i, t in enumerate(targets)]))\n",
    "#with open('/n/sd7/trung/csp/data/erica/inputs.txt', 'w') as f:\n",
    "#    f.write('\\n'.join(filepaths))\n",
    "    \n",
    "#with open('/n/sd7/trung/csp/data/erica/targets.txt', 'w') as f:\n",
    "#    f.write('\\n'.join(t[4] for t in targets))\n",
    "    \n",
    "with open('/n/sd7/trung/csp/data/erica/%s_notag.txt' % mode, 'w') as f:\n",
    "    f.write('\\n'.join([path + ' ' + '2 ' + target[5] + ' 1' for path, target in zip(filepaths, targets)]))\n",
    "    \n",
    "with open('/n/sd7/trung/csp/data/erica/%s_notag_context.txt' % mode, 'w') as f:\n",
    "    for i in range(len(filepaths)):\n",
    "        if targets[i][6]:\n",
    "            f.write('%s\\t%s %s %s\\t2 %s 1' % (filepaths[i], '0', ' '.join('0' * (TAG_COUNT)), targets[i][4], targets[i][5]))\n",
    "        else:\n",
    "            f.write('%s\\t%s %s %s\\t2 %s 1' % (filepaths[i], ('0' if targets[i - 1][3] == targets[i][3] else '1'), targets[i - 1][4], targets[i][4], targets[i][5]))\n",
    "        if i != len(filepaths) - 1: f.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wav[test[0]:test[1]].export(\"/n/sd7/trung/test.wav\", format='wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IPython.display.Audio(\"/n/sd7/trung/test.wav\", autoplay=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wavfile = \"/n/sd7/trung/data/erica/htk/20171130_07/0041_U.htk\"\n",
    "wavfile = wavfile.replace('htk', 'wav')\n",
    "#feat = get_features(wavfile)\n",
    "#print(feat)\n",
    "IPython.display.Audio(wavfile, autoplay=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
