{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tensorflow.python.platform import gfile\n",
    "import scipy.io.wavfile as wav\n",
    "from python_speech_features import *\n",
    "import numpy as np\n",
    "from subprocess import call\n",
    "from struct import unpack, pack\n",
    "from tqdm import tqdm as tqdm\n",
    "\n",
    "DATA_DIR = os.path.join(\"/n/sd7/trung/csp\", \"data\", \"vivos\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word count: 4861\n",
      "Char count: 91\n",
      "dict_keys(['_', 'ầ', 'ự', 'ẽ', 'ẫ', 'ố', 'é', 'ý', 'c', 'á', 'y', 'i', 'à', 'x', 'ú', 'ằ', 'ũ', 'ể', 'ớ', 'ử', 'ư', 'ơ', 'ỉ', 'õ', 'ẵ', 'ó', 'ả', 'ĩ', 'n', 'o', 'ỏ', 'ù', 'ộ', 'u', 'ữ', 'ệ', 'ỵ', 'ê', 'ã', 's', 'đ', 'ứ', 'ủ', 'ă', 'ẩ', 'ỹ', 'ụ', 'a', 'ì', 'e', 'm', 'b', 'ạ', 'd', 'ỡ', 'l', 'ẻ', 'ờ', 'k', 'ợ', '4', 'ị', 'ỷ', 'ẳ', 'p', 'ồ', 'ễ', 'ở', 'ẹ', 'í', 'â', 'h', 'ấ', 'ắ', 'ỳ', 'v', 'ô', 'g', 'ọ', 'ế', 'ổ', 'è', 'q', 'ề', 't', 'ậ', 'ò', 'r', 'ỗ', 'ừ', 'ặ'])\n"
     ]
    }
   ],
   "source": [
    "mode = \"train\"\n",
    "\n",
    "wset = set()\n",
    "with open(os.path.join(DATA_DIR, mode, \"prompts.txt\"), encoding=\"utf-8\") as f:\n",
    "    for s in f.read().split('\\n'):\n",
    "        s = s.replace(':', '')\n",
    "        words = s.split(' ')[1:]\n",
    "        for word in words: \n",
    "            if word != '': wset.add(word.lower())\n",
    "\n",
    "# word-unit\n",
    "with open(os.path.join(DATA_DIR, \"vocab_words.txt\"), \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(\"<oov>\\n\")\n",
    "    f.write(\"\\n\".join([\"%s\" % (word) for _, word in\n",
    "        enumerate(list(wset)) if word != \"\"]))\n",
    "\n",
    "# char-unit\n",
    "cset = set()\n",
    "for word in wset: cset |= set(word)\n",
    "with open(os.path.join(DATA_DIR, \"vocab_chars.txt\"), \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(\"_\\n\")\n",
    "    f.write(\"\\n\".join([\"%s\" % (c) for _, c in\n",
    "        enumerate(list(cset)) if c != \"\"]))\n",
    "\n",
    "vocab_word = { word: i for i, word in enumerate(open(os.path.join(DATA_DIR, \"vocab_words.txt\")).read().split('\\n')) }\n",
    "vocab_char = { word: i for i, word in enumerate(open(os.path.join(DATA_DIR, \"vocab_chars.txt\")).read().split('\\n')) }\n",
    "\n",
    "print(\"Word count:\", len(vocab_word))\n",
    "print(\"Char count:\", len(vocab_char))\n",
    "print(vocab_char.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 11661/11661 [09:16<00:00, 20.94it/s]\n"
     ]
    }
   ],
   "source": [
    "# get mean\n",
    "mean = np.array([0] * 120)\n",
    "var = np.array([0] * 120)\n",
    "count = 0\n",
    "\n",
    "mode = \"train\"\n",
    "with open(os.path.join(DATA_DIR, mode, \"prompts.txt\"), encoding=\"utf-8\") as f:\n",
    "    lines = f.read().split(\"\\n\")\n",
    "    for i, s in tqdm(list(enumerate(lines)), desc=mode):\n",
    "        filename = s.split(' ')[0]\n",
    "        if filename == \"\": continue\n",
    "        wav_filename = os.path.join(DATA_DIR, mode, \"waves\", filename.split('_')[0], filename + \".wav\")\n",
    "        npy_filename = os.path.join(DATA_DIR, mode, \"npy\", filename.split('_')[0], filename + \".npy\")\n",
    "\n",
    "        filename = os.path.join(DATA_DIR, mode, \"feature\", filename + \".htk\")\n",
    "        call([\n",
    "            \"/n/sd7/trung/bin/htk/HTKTools/HCopy\",\n",
    "            wav_filename,\n",
    "            filename,\n",
    "            \"-C\", \"/n/sd7/trung/config.lmfb.40ch\"\n",
    "        ])\n",
    "        fh = open(filename, \"rb\")\n",
    "        spam = fh.read(12)\n",
    "        nSamples, sampPeriod, sampSize, parmKind = unpack(\">IIHH\", spam)\n",
    "        veclen = int(sampSize / 4)\n",
    "        fh.seek(12, 0)\n",
    "        dat = np.fromfile(fh, dtype=np.float32)\n",
    "        dat = dat.reshape(len(dat) // veclen, veclen)\n",
    "        dat = dat.byteswap()\n",
    "        fh.close()\n",
    "\n",
    "        for k in range(len(dat)):\n",
    "            updated_mean = (mean * count + dat[k]) / (count + 1)\n",
    "            var = (count * var + (dat[k] - mean) * (dat[k] - updated_mean)) / (count + 1)\n",
    "            mean = updated_mean\n",
    "            count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.38207185 2.46174385 3.91958839 4.37270776 4.81470204 4.82823999\n",
      " 4.66911868 4.72899695 4.84014002 4.89239347 4.64227326 4.89814603\n",
      " 4.8223888  4.44516746 4.2941552  4.08150563 3.86376774 3.77136156\n",
      " 3.64902139 3.47856072 3.59918557 3.59006455 3.62087033 3.67942348\n",
      " 3.46131254 3.65319249 3.64677982 3.62159319 3.67318854 3.72135487\n",
      " 3.64235773 3.35510406 2.90820098 2.40895137 2.19363585 2.17407766\n",
      " 2.02689838 1.96658986 2.04127664 2.07970579 0.05948409 0.06667083\n",
      " 0.0807493  0.09019495 0.10737468 0.12435774 0.13387861 0.13918603\n",
      " 0.14520674 0.15264976 0.15092295 0.14648077 0.14080602 0.13070525\n",
      " 0.12424339 0.11949739 0.11472416 0.11344693 0.11198919 0.10951017\n",
      " 0.1091674  0.10774977 0.10555033 0.10365875 0.0996435  0.10382715\n",
      " 0.10900165 0.11181899 0.11458519 0.11524595 0.11400782 0.10877169\n",
      " 0.09797947 0.08491204 0.0792967  0.08007722 0.07654737 0.07570489\n",
      " 0.07636243 0.0745485  0.01118224 0.01146189 0.01261451 0.01341283\n",
      " 0.01589817 0.01920197 0.0211048  0.0215637  0.02192232 0.02256951\n",
      " 0.0218693  0.02018886 0.01911716 0.01766232 0.01669561 0.0162614\n",
      " 0.01562602 0.01542287 0.01533621 0.01511595 0.01502663 0.01482611\n",
      " 0.01437037 0.01405008 0.01359134 0.01439552 0.01527073 0.01564561\n",
      " 0.0158929  0.01596542 0.01598598 0.01576859 0.01483234 0.01319818\n",
      " 0.01229643 0.01238414 0.0120411  0.01202061 0.01211994 0.01182702]\n"
     ]
    }
   ],
   "source": [
    "print(var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test: 100%|██████████| 761/761 [00:17<00:00, 43.62it/s]\n",
      "train: 100%|██████████| 11661/11661 [05:35<00:00, 34.76it/s]\n"
     ]
    }
   ],
   "source": [
    "outputs = {'train': [], 'test': []}\n",
    "\n",
    "for mode in [\"test\", \"train\"]:\n",
    "    with open(os.path.join(DATA_DIR, mode, \"prompts.txt\"), encoding=\"utf-8\") as f:\n",
    "        lines = f.read().split(\"\\n\")\n",
    "        for i, s in tqdm(list(enumerate(lines)), desc=mode):\n",
    "            filename = s.split(' ')[0]\n",
    "            if filename == \"\": continue\n",
    "            wav_filename = os.path.join(DATA_DIR, mode, \"waves\", filename.split('_')[0], filename + \".wav\")\n",
    "            npy_filename = os.path.join(DATA_DIR, mode, \"npy\", filename + \".npy\")\n",
    "\n",
    "            if True:\n",
    "                # (rate, sig) = wav.read(wav_filename)\n",
    "                htk_filename = os.path.join(DATA_DIR, mode, \"feature\", filename + \".htk\")\n",
    "                fh = open(htk_filename, \"rb\")\n",
    "                spam = fh.read(12)\n",
    "                nSamples, sampPeriod, sampSize, parmKind = unpack(\">IIHH\", spam)\n",
    "                veclen = int(sampSize / 4)\n",
    "                fh.seek(12, 0)\n",
    "                dat = np.fromfile(fh, dtype=np.float32)\n",
    "                dat = dat.reshape(len(dat) // veclen, veclen)\n",
    "                dat = dat.byteswap()\n",
    "                fh.close()\n",
    "\n",
    "                dat = (dat - mean) / np.sqrt(var)\n",
    "                np.save(npy_filename, dat)\n",
    "\n",
    "            trans = s.lower().split(' ', 1)[1].replace(' ', '_').replace(':', '')\n",
    "            outputs[mode].append(dict(\n",
    "                filename=npy_filename,\n",
    "                target_word=' '.join([str(vocab_word[w.lower()]) if w in words else '0' \\\n",
    "                    for w in trans.split(' ')]),\n",
    "                target_char=' '.join([str(vocab_char[c.lower()]) for c in trans]),\n",
    "                trans_words=' '.join(s.lower().split(' ')[1:])\n",
    "            ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "for mode in [\"test\", \"train\"]:\n",
    "    for unit in [\"word\", \"char\"]:\n",
    "        with open(os.path.join(DATA_DIR, \"%s_%s\" % (unit, mode) + '.csv'), 'w') as f:\n",
    "            f.write('\\t'.join(['sound', 'target', 'trans']) + '\\n')\n",
    "            for o in outputs[mode]:\n",
    "                f.write('\\t'.join([\n",
    "                    o['filename'],\n",
    "                    o['target_%s' % unit],\n",
    "                    o['trans_words']\n",
    "                ]) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = np.load(os.path.join(DATA_DIR, \"mean.npy\"))\n",
    "var = np.load(os.path.join(DATA_DIR, \"var.npy\"))\n",
    "\n",
    "def get_features_npy(infile, outfile):\n",
    "    fh = open(infile, \"rb\")\n",
    "    spam = fh.read(12)\n",
    "    nSamples, sampPeriod, sampSize, parmKind = unpack(\">IIHH\", spam)\n",
    "    veclen = int(sampSize / 4)\n",
    "    fh.seek(12, 0)\n",
    "    dat = np.fromfile(fh, dtype=np.float32)\n",
    "    dat = dat.reshape(len(dat) // veclen, veclen)\n",
    "    dat = dat.byteswap()\n",
    "    fh.close()\n",
    "    \n",
    "    dat = (dat - mean) / np.sqrt(var)\n",
    "    # print(len(dat), dat)\n",
    "    np.save(outfile, dat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
