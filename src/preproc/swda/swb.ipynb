{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from swda import Transcript\n",
    "import glob, os, re, random, pathlib\n",
    "import numpy as np\n",
    "from tqdm import tqdm as tqdm\n",
    "from collections import namedtuple\n",
    "import utils\n",
    "from IPython.display import HTML, display\n",
    "import pandas as pd\n",
    "from pydub import AudioSegment\n",
    "\n",
    "DATA_PATH = '/n/sd7/trung/csp/data/swbd'\n",
    "FEATURE_PATH = '/n/sd7/trung/csp/data/swbd/feature/numpy'\n",
    "htk_path = lambda dlgid, caller: os.path.join(DATA_FOLDER, \"htk\", \"swbd\", \"sw0%s-%s.htk\" % (dlgid, caller))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_utts = {}\n",
    "dlg_utts = {}\n",
    "                                                                                                                                                                                                                                                                                                                                                    \n",
    "for transfile in tqdm(list(glob.glob(os.path.join(DATA_PATH, \"swb_ms98_transcriptions\", \"*\", '*', \"*word.text\"))), desc=\"Load transcript\"):\n",
    "    dlgid = os.path.basename(transfile)[2:6]\n",
    "    \n",
    "    if not os.path.exists(os.path.join(DATA_FOLDER, \"wav\", dlgid)):\n",
    "        os.mkdir(os.path.join(DATA_FOLDER, \"wav\", dlgid))\n",
    "                                                                                                                                \n",
    "    if dlgid not in trans_utts: trans_utts[dlgid] = []\n",
    "    if dlgid not in dlg_utts: dlg_utts[dlgid] = []\n",
    "        \n",
    "    trans_utts[dlgid] += utils.read_word_transcript_file(transfile)\n",
    "    trans_utts[dlgid].sort(key=lambda utt: utt['words'][0]['start'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_word(word):\n",
    "    word = word.lower()\n",
    "    word = word.replace('_1', '')\n",
    "    return word\n",
    "    \n",
    "dlg_utts = { dlgid: [dict(\n",
    "    id=i,\n",
    "    start=utt['words'][0]['start'], \n",
    "    end=utt['words'][-1]['end'],\n",
    "    caller=utt['caller'],\n",
    "    trans_words=[map_word(word['word']) for word in utt['words']]\n",
    ") for i, utt in enumerate(trans_utts[dlgid])] for dlgid in trans_utts }\n",
    "\n",
    "print(\"Dataset Overview\")\n",
    "print(\"Conversations:\", len(dlg_utts))\n",
    "print(\"Utterances:\", sum([len(dlg_utts[id]) for id in dlg_utts]))\n",
    "print(\"Utterances' length (sum): %.2f hours\" % (sum([sum([utt['end'] - utt['start'] for utt in dlg_utts[id]]) for id in dlg_utts]) / 3600 / 100))\n",
    "print(\"Total length: %.2f hours\" % (sum([dlg_utts[id][-1]['end'] for id in dlg_utts]) / 3600 / 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of a conversation\n",
    "utts = [[utt['caller'], utt['start'], utt['end'], ' '.join(utt['trans_words'])] for utt in dlg_utts[random.choice(list(dlg_utts.keys()))]]\n",
    "pd.set_option('display.max_rows', 10)\n",
    "pd.DataFrame(utts, columns=[\"caller\", \"start\", \"end\", \"transcript\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract speech\n",
    "from htk import read as read_htk\n",
    "sil_duration = 25  # padding\n",
    "PREFIX = \"swb_padding25\"\n",
    "\n",
    "total_frame_num = 0\n",
    "\n",
    "global_mean = None\n",
    "global_std = None\n",
    "feature_dim = 120\n",
    "input_data_std = np.zeros((feature_dim,), dtype=np.float32)\n",
    "input_data_sum = np.zeros((feature_dim,), dtype=np.float32)\n",
    "\n",
    "for desc in [\"calculate mean\", \"calculate std\", \"extract speech\"]:\n",
    "    for dlgid in tqdm(dlg_utts, desc=desc):\n",
    "        pathlib.Path(os.path.join(FEATURE_PATH, PREFIX, dlgid)).mkdir(parents=True, exist_ok=True)\n",
    "        for caller in ['A', 'B']:\n",
    "            utterance_dict = list(filter(lambda utt: utt['caller'] == caller, dlg_utts[dlgid]))\n",
    "            #print(len(utterance_dict))\n",
    "            audio_path = htk_path(dlgid, caller)\n",
    "\n",
    "            input_data, _, _ = read_htk(audio_path)\n",
    "            input_data_dict = {}\n",
    "            total_frame_num = 0\n",
    "            end_frame_pre = 0\n",
    "        \n",
    "            for i, utt in enumerate(utterance_dict):\n",
    "                start_frame, end_frame = utt['start'], utt['end']\n",
    "                if i == 0:\n",
    "                    start_frame_extend = max(start_frame - sil_duration, 0)\n",
    "                    start_frame_next = utterance_dict[1]['start'] if len(utterance_dict) > 1 else input_data.shape[0]\n",
    "                    end_frame_extend = max(end_frame, min(end_frame + sil_duration, (start_frame_next + end_frame) // 2))\n",
    "                    end_frame_pre = end_frame\n",
    "                elif i == len(utterance_dict) - 1:\n",
    "                    start_frame_extend = max(start_frame - sil_duration, (start_frame + end_frame_pre) // 2)\n",
    "                    end_frame_extend = max(end_frame, min(end_frame + sil_duration, input_data.shape[0]))\n",
    "                else:\n",
    "                    start_frame_extend = max(start_frame - sil_duration, (start_frame + end_frame_pre) // 2)\n",
    "                    start_frame_next = utterance_dict[i + 1]['start']\n",
    "                    if end_frame > start_frame_next:\n",
    "                        print(\"Warning: utterances are overlapping.\")\n",
    "                    end_frame_extend = max(end_frame, min(end_frame + sil_duration, (start_frame_next + end_frame) // 2))\n",
    "                    end_frame_pre = end_frame\n",
    "                \n",
    "                input_data_utt = input_data[start_frame_extend:end_frame_extend]\n",
    "                input_data_sum += np.sum(input_data_utt, axis=0)\n",
    "        \n",
    "                if global_mean is not None:\n",
    "                    if global_std is None:  # calculate std\n",
    "                        input_data_std += np.sum(np.abs(input_data_utt - global_mean) ** 2, axis=0)\n",
    "                    else:  # save\n",
    "                        input_utt = (input_data_utt - global_mean) / global_std\n",
    "                        #print(os.path.join(DATA_FOLDER, \"feature\", \"numpy\", PREFIX, dlgid, \"%s%s.npy\" % (utt['id'], caller)))\n",
    "                        np.save(os.path.join(FEATURE_PATH, PREFIX, dlgid, \"%s%s.npy\" % (utt['id'], utt['caller'])), input_utt)\n",
    "                total_frame_num += end_frame_extend - start_frame_extend\n",
    "                \n",
    "        if global_mean is not None:\n",
    "            if global_std is None:\n",
    "                global_std = np.sqrt(input_data_std / (total_frame_num - 1))\n",
    "        else:\n",
    "            global_mean = input_data_sum / total_frame_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_keys = list(dlg_utts.keys())\n",
    "dlg_ids = {}\n",
    "dlg_ids['test'] = ['2689', '2389', '3016', '2898', '2679', '3567', '2373', '3250', '2478', '2929', '4078', '2821', '4770', '3170', '3198', '2064', '2562', '3271', '3061', '2982']\n",
    "dlg_ids['dev'] = ['3208', '2935', '3162', '2854', '2692', '2437', '3711', '2511', '3203', '3257', '2386', '3290', '3184', '2495', '2959', '3231', '2723', '3280', '3686', '3102', '3346', '2292', '3057', '3214', '2524', '2884', '2693', '2471', '2675', '2834', '2457', '3276', '3013', '2432', '2991', '3270', '2205', '2967', '2623', '3352']\n",
    "dlg_ids['dev_train'] = [id for id in _keys if id not in dlg_ids['test']]\n",
    "dlg_ids['train'] = [id for id in _keys if id not in dlg_ids['test'] and id not in dlg_ids['dev']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_vocab(dlgs, output=None): # build words\n",
    "    vocab_freq = {}\n",
    "    for dlgid in dlgs:\n",
    "        if dlgid not in dlg_utts: continue\n",
    "        for utt in dlg_utts[dlgid]:\n",
    "            for word in utt['trans_words']:\n",
    "                word = word.lower()\n",
    "                if word == '': continue\n",
    "                if not 'a' <= word[0] <= 'z': continue\n",
    "                if word in vocab_freq: vocab_freq[word] += 1\n",
    "                else: vocab_freq[word] = 1\n",
    "                    \n",
    "    words = list(vocab_freq.keys())\n",
    "    words.sort(key=lambda word: vocab_freq[word], reverse=True)\n",
    "    words = words[:-1]\n",
    "    words = [\"<oov>\"] + words\n",
    "    \n",
    "    if output is not None:\n",
    "        with open(output, 'w') as f:\n",
    "            f.write('\\n'.join(words))\n",
    "    \n",
    "    return { word: i for i, word in enumerate(words) }\n",
    "\n",
    "vocab = build_vocab(dlg_ids['dev_train'], output=os.path.join(DATA_FOLDER, \"vocab\", \"words_swb.txt\"))\n",
    "print(\"Vocab Size:\", len(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PREFIX = \"swb\"\n",
    "\n",
    "headers = ['dialog_id', 'sound', 'start', 'end', 'sound_len', 'caller', 'dialog_act', 'text', 'target', 'predicted_text']\n",
    "for mode in dlg_ids.keys():\n",
    "    with open(os.path.join(DATA_FOLDER, '%s_%s.csv' % (PREFIX, mode)), 'w') as fo:\n",
    "        fo.write('\\t'.join(headers) + '\\n')\n",
    "        for dlgid in tqdm(dlg_ids[mode], desc=mode):\n",
    "            if dlgid not in dlg_utts: continue\n",
    "            for utt in dlg_utts[dlgid]:\n",
    "                if len(utt['trans_words']) == 0: continue\n",
    "                if utt['start'] >= utt['end'] - 5: continue\n",
    "                fo.write('\\t'.join([\n",
    "                    dlgid,\n",
    "                    os.path.join(DATA_FOLDER, \"feature\", \"numpy\", \"swda_full\", dlgid, \"%d%s.npy\" % (utt['id'], utt['caller'])), \n",
    "                    str(utt['start']), str(utt['end']),\n",
    "                    str(utt['end'] - utt['start']),\n",
    "                    utt['caller'],\n",
    "                    \"0\",\n",
    "                    ' '.join([word.lower() for word in utt['trans_words']]),\n",
    "                    ' '.join([str(vocab[word.lower()]) if word.lower() in vocab else '0' for word in utt['trans_words']]),\n",
    "                    ' '.join([str(vocab[word.lower()]) if word.lower() in vocab else '0' for word in utt['trans_words']])\n",
    "                ]) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
