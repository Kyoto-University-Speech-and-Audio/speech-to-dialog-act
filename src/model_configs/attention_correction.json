{
  "name": "attention_correction",
  "model": "attention_correction",
  "dataset": "aps",
  "input_unit": "word",

  "eos_index": 1,
  "sos_index": 2,
  "beam_width": 0,
  "encoder_type": "bilstm",
  "encoder_num_units": 640,
  "decoder_num_units": 640,
  "attention_layer_size": 640,

  "length_penalty_weight": 0.5
}
